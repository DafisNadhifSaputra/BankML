{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tvAKGat01Sd"
      },
      "source": [
        "# **Submission Akhir BMLP - Analisis Klasifikasi**\n",
        "**Nama:** Dafis Nadhif Saputra  \n",
        "**Topik:** Implementasi Model Klasifikasi untuk Prediksi Target dari Hasil Clustering\n",
        "\n",
        "Notebook ini berisi implementasi berbagai algoritma klasifikasi untuk memprediksi target berdasarkan hasil clustering yang telah dilakukan sebelumnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "## Konsep Klasifikasi\n",
        "\n",
        "**Klasifikasi** adalah teknik machine learning untuk memprediksi kategori atau label dari data baru berdasarkan pola yang dipelajari dari data training. Dalam analisis ini, kita akan menggunakan hasil clustering sebelumnya sebagai target untuk melatih model klasifikasi.\n",
        "\n",
        "**Analogi sederhana:** Seperti dokter yang mendiagnosis penyakit berdasarkan gejala-gejala yang diamati, model klasifikasi memprediksi cluster mana yang paling cocok untuk data transaksi baru berdasarkan karakteristik finansialnya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "\n",
        "#Type your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**\n",
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame.\n",
        "\n",
        "## Import Library dan Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/data_clustering.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bCsep0NZ0LUf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionAmount</th>\n",
              "      <th>TransactionType</th>\n",
              "      <th>Location</th>\n",
              "      <th>Channel</th>\n",
              "      <th>CustomerAge</th>\n",
              "      <th>CustomerOccupation</th>\n",
              "      <th>TransactionDuration</th>\n",
              "      <th>LoginAttempts</th>\n",
              "      <th>AccountBalance</th>\n",
              "      <th>TransactionAmount_binned</th>\n",
              "      <th>CustomerAge_binned</th>\n",
              "      <th>TransactionAmount_binned_encoded</th>\n",
              "      <th>CustomerAge_binned_encoded</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007207</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>0</td>\n",
              "      <td>0.244828</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.336832</td>\n",
              "      <td>Low</td>\n",
              "      <td>Senior</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.195940</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0</td>\n",
              "      <td>0.451724</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.918055</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Senior</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.065680</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>3</td>\n",
              "      <td>0.158621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.068637</td>\n",
              "      <td>Low</td>\n",
              "      <td>Young</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.096016</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>3</td>\n",
              "      <td>0.051724</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.569198</td>\n",
              "      <td>Low</td>\n",
              "      <td>Young</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.047888</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.558621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045738</td>\n",
              "      <td>Low</td>\n",
              "      <td>Young</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionAmount  TransactionType  Location  Channel  CustomerAge  \\\n",
              "0           0.007207                1        36        0     0.838710   \n",
              "1           0.195940                1        15        0     0.806452   \n",
              "2           0.065680                1        23        2     0.016129   \n",
              "3           0.096016                1        33        2     0.129032   \n",
              "4           0.047888                1        28        0     0.000000   \n",
              "\n",
              "   CustomerOccupation  TransactionDuration  LoginAttempts  AccountBalance  \\\n",
              "0                   0             0.244828            0.0        0.336832   \n",
              "1                   0             0.451724            0.0        0.918055   \n",
              "2                   3             0.158621            0.0        0.068637   \n",
              "3                   3             0.051724            0.0        0.569198   \n",
              "4                   3             0.558621            0.0        0.045738   \n",
              "\n",
              "  TransactionAmount_binned CustomerAge_binned  \\\n",
              "0                      Low             Senior   \n",
              "1                   Medium             Senior   \n",
              "2                      Low              Young   \n",
              "3                      Low              Young   \n",
              "4                      Low              Young   \n",
              "\n",
              "   TransactionAmount_binned_encoded  CustomerAge_binned_encoded  Target  \n",
              "0                                 1                           1       1  \n",
              "1                                 2                           1       0  \n",
              "2                                 1                           2       2  \n",
              "3                                 1                           2       1  \n",
              "4                                 1                           2       2  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Shape: (2182, 14)\n",
            "\n",
            "Column Names: ['TransactionAmount', 'TransactionType', 'Location', 'Channel', 'CustomerAge', 'CustomerOccupation', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'TransactionAmount_binned', 'CustomerAge_binned', 'TransactionAmount_binned_encoded', 'CustomerAge_binned_encoded', 'Target']\n",
            "\n",
            "Data Types:\n",
            "TransactionAmount                   float64\n",
            "TransactionType                       int64\n",
            "Location                              int64\n",
            "Channel                               int64\n",
            "CustomerAge                         float64\n",
            "CustomerOccupation                    int64\n",
            "TransactionDuration                 float64\n",
            "LoginAttempts                       float64\n",
            "AccountBalance                      float64\n",
            "TransactionAmount_binned             object\n",
            "CustomerAge_binned                   object\n",
            "TransactionAmount_binned_encoded      int64\n",
            "CustomerAge_binned_encoded            int64\n",
            "Target                                int64\n",
            "dtype: object\n",
            "\n",
            "Missing Values:\n",
            "TransactionAmount                   0\n",
            "TransactionType                     0\n",
            "Location                            0\n",
            "Channel                             0\n",
            "CustomerAge                         0\n",
            "CustomerOccupation                  0\n",
            "TransactionDuration                 0\n",
            "LoginAttempts                       0\n",
            "AccountBalance                      0\n",
            "TransactionAmount_binned            0\n",
            "CustomerAge_binned                  0\n",
            "TransactionAmount_binned_encoded    0\n",
            "CustomerAge_binned_encoded          0\n",
            "Target                              0\n",
            "dtype: int64\n",
            "\n",
            "Unique values in categorical columns:\n",
            "TransactionAmount_binned: ['Low' 'Medium' 'Very High' 'High']\n",
            "CustomerAge_binned: ['Senior' 'Young' 'Adult']\n"
          ]
        }
      ],
      "source": [
        "# Periksa informasi dataset\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nColumn Names:\", df.columns.tolist())\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\nUnique values in categorical columns:\")\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    print(f\"{col}: {df[col].unique()[:10]}\")  # Show first 10 unique values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkPem5eWL2UP"
      },
      "source": [
        "# **3. Data Splitting**\n",
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set).\n",
        "\n",
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OubAW-7ONKVj"
      },
      "outputs": [],
      "source": [
        "# Menggunakan train_test_split() untuk melakukan pembagian dataset.\n",
        "\n",
        "X = df.drop('Target', axis=1)\n",
        "y = df['Target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train columns: ['TransactionAmount', 'TransactionType', 'Location', 'Channel', 'CustomerAge', 'CustomerOccupation', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'TransactionAmount_binned', 'CustomerAge_binned', 'TransactionAmount_binned_encoded', 'CustomerAge_binned_encoded']\n",
            "\n",
            "X_train data types:\n",
            "TransactionAmount                   float64\n",
            "TransactionType                       int64\n",
            "Location                              int64\n",
            "Channel                               int64\n",
            "CustomerAge                         float64\n",
            "CustomerOccupation                    int64\n",
            "TransactionDuration                 float64\n",
            "LoginAttempts                       float64\n",
            "AccountBalance                      float64\n",
            "TransactionAmount_binned             object\n",
            "CustomerAge_binned                   object\n",
            "TransactionAmount_binned_encoded      int64\n",
            "CustomerAge_binned_encoded            int64\n",
            "dtype: object\n",
            "\n",
            "Kolom yang masih berisi string:\n",
            "TransactionAmount_binned: ['Very High' 'Low' 'Medium' 'High']\n",
            "CustomerAge_binned: ['Young' 'Adult' 'Senior']\n"
          ]
        }
      ],
      "source": [
        "# Periksa kolom-kolom dalam X_train\n",
        "print(\"X_train columns:\", X_train.columns.tolist())\n",
        "print(\"\\nX_train data types:\")\n",
        "print(X_train.dtypes)\n",
        "print(\"\\nKolom yang masih berisi string:\")\n",
        "for col in X_train.select_dtypes(include=['object']).columns:\n",
        "    print(f\"{col}: {X_train[col].unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sebelum preprocessing:\n",
            "X_train shape: (1745, 13)\n",
            "X_test shape: (437, 13)\n",
            "\n",
            "Setelah preprocessing:\n",
            "X_train_clean shape: (1745, 11)\n",
            "X_test_clean shape: (437, 11)\n",
            "\n",
            "Data types setelah cleaning:\n",
            "TransactionAmount                   float64\n",
            "TransactionType                       int64\n",
            "Location                              int64\n",
            "Channel                               int64\n",
            "CustomerAge                         float64\n",
            "CustomerOccupation                    int64\n",
            "TransactionDuration                 float64\n",
            "LoginAttempts                       float64\n",
            "AccountBalance                      float64\n",
            "TransactionAmount_binned_encoded      int64\n",
            "CustomerAge_binned_encoded            int64\n",
            "dtype: object\n",
            "\n",
            "Kolom yang masih berisi string:\n",
            "Jumlah kolom object: 0\n",
            "Tidak ada kolom string lagi - siap untuk modeling!\n"
          ]
        }
      ],
      "source": [
        "# PERBAIKAN: Hapus kolom yang masih berisi string karena sudah ada versi encoded-nya\n",
        "print(\"Sebelum preprocessing:\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "# Hapus kolom string dan hanya gunakan versi encoded\n",
        "columns_to_drop = ['TransactionAmount_binned', 'CustomerAge_binned']\n",
        "X_train_clean = X_train.drop(columns=columns_to_drop)\n",
        "X_test_clean = X_test.drop(columns=columns_to_drop)\n",
        "\n",
        "print(\"\\nSetelah preprocessing:\")\n",
        "print(f\"X_train_clean shape: {X_train_clean.shape}\")\n",
        "print(f\"X_test_clean shape: {X_test_clean.shape}\")\n",
        "\n",
        "# Verifikasi tidak ada lagi kolom object/string\n",
        "print(\"\\nData types setelah cleaning:\")\n",
        "print(X_train_clean.dtypes)\n",
        "print(\"\\nKolom yang masih berisi string:\")\n",
        "object_cols = X_train_clean.select_dtypes(include=['object']).columns\n",
        "print(f\"Jumlah kolom object: {len(object_cols)}\")\n",
        "if len(object_cols) > 0:\n",
        "    for col in object_cols:\n",
        "        print(f\"{col}: {X_train_clean[col].unique()}\")\n",
        "else:\n",
        "    print(\"Tidak ada kolom string lagi - siap untuk modeling!\")\n",
        "\n",
        "# Update variabel X_train dan X_test\n",
        "X_train = X_train_clean\n",
        "X_test = X_test_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVPbB03CMhTT"
      },
      "source": [
        "# **4. Membangun Model Klasifikasi**\n",
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "## Data Preparation untuk Klasifikasi\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Menggunakan algoritma klasifikasi yaitu Decision Tree.\n",
        "2. Latih model menggunakan data yang sudah dipisah."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Results:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Buatlah model klasifikasi menggunakan Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi pada data test\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluasi model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Decision Tree Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "P_AakAxghYv-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['../models/decision_tree_model.h5']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menyimpan Model\n",
        "import joblib\n",
        "joblib.dump(dt_model, '../models/decision_tree_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epO4HhrzBXMg"
      },
      "source": [
        "## Model Exploration - Perbandingan Algoritma Klasifikasi\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNOEZk24uiXu"
      },
      "source": [
        "## Hyperparameter Tuning Model Terbaik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kB_8LIWMATl6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Melatih model menggunakan algoritma klasifikasi selain Decision Tree.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# SVM\n",
        "svm_model = SVC(random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# KNN\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bRlKm5BVAT91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Model Comparison ===\n",
            "Random Forest - Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
            "SVM - Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
            "KNN - Accuracy: 0.9977, Precision: 0.9977, Recall: 0.9977, F1-Score: 0.9977\n",
            "Decision Tree - Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada seluruh algoritma yang sudah dibuat.\n",
        "\n",
        "# Evaluasi Random Forest\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "rf_precision = precision_score(y_test, rf_pred, average='weighted')\n",
        "rf_recall = recall_score(y_test, rf_pred, average='weighted')\n",
        "rf_f1 = f1_score(y_test, rf_pred, average='weighted')\n",
        "\n",
        "# Evaluasi SVM\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "svm_precision = precision_score(y_test, svm_pred, average='weighted')\n",
        "svm_recall = recall_score(y_test, svm_pred, average='weighted')\n",
        "svm_f1 = f1_score(y_test, svm_pred, average='weighted')\n",
        "\n",
        "# Evaluasi KNN\n",
        "knn_pred = knn_model.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "knn_precision = precision_score(y_test, knn_pred, average='weighted')\n",
        "knn_recall = recall_score(y_test, knn_pred, average='weighted')\n",
        "knn_f1 = f1_score(y_test, knn_pred, average='weighted')\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(\"=== Model Comparison ===\")\n",
        "print(f\"Random Forest - Accuracy: {rf_accuracy:.4f}, Precision: {rf_precision:.4f}, Recall: {rf_recall:.4f}, F1-Score: {rf_f1:.4f}\")\n",
        "print(f\"SVM - Accuracy: {svm_accuracy:.4f}, Precision: {svm_precision:.4f}, Recall: {svm_recall:.4f}, F1-Score: {svm_f1:.4f}\")\n",
        "print(f\"KNN - Accuracy: {knn_accuracy:.4f}, Precision: {knn_precision:.4f}, Recall: {knn_recall:.4f}, F1-Score: {knn_f1:.4f}\")\n",
        "print(f\"Decision Tree - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dUPItkbXBNkO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['../models/explore_KNN_classification.h5']"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menyimpan Model Selain Decision Tree\n",
        "# Model ini bisa lebih dari satu\n",
        "import joblib\n",
        "joblib.dump(rf_model, '../models/explore_RandomForest_classification.h5')\n",
        "joblib.dump(svm_model, '../models/explore_SVM_classification.h5')\n",
        "joblib.dump(knn_model, '../models/explore_KNN_classification.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u23H2guj-h9h"
      },
      "source": [
        "Hyperparameter Tuning Model\n",
        "\n",
        "Pilih salah satu algoritma yang ingin Anda tuning\n",
        "\n",
        "## Model Evaluation dan Interpretasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dFCTxJJq-m-l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for Random Forest:\n",
            "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "# Lakukan Hyperparameter Tuning dan Latih ulang.\n",
        "# Lakukan dalam satu cell ini saja.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Parameter untuk tuning Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# GridSearchCV untuk Random Forest\n",
        "rf_grid = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the grid search\n",
        "rf_grid.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "rf_tuned = rf_grid.best_estimator_\n",
        "print(\"Best parameters for Random Forest:\")\n",
        "print(rf_grid.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1g6EPSSWxjcQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Tuned Random Forest Results ===\n",
            "Accuracy: 0.9977\n",
            "Precision: 0.9977\n",
            "Recall: 0.9977\n",
            "F1-Score: 0.9977\n",
            "\n",
            "=== Comparison (Before vs After Tuning) ===\n",
            "Before Tuning - Accuracy: 1.0000, F1-Score: 1.0000\n",
            "After Tuning - Accuracy: 0.9977, F1-Score: 0.9977\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada algoritma yang sudah dituning.\n",
        "\n",
        "# Prediksi dengan model yang sudah di-tuning\n",
        "rf_tuned_pred = rf_tuned.predict(X_test)\n",
        "\n",
        "# Evaluasi model yang sudah di-tuning\n",
        "rf_tuned_accuracy = accuracy_score(y_test, rf_tuned_pred)\n",
        "rf_tuned_precision = precision_score(y_test, rf_tuned_pred, average='weighted')\n",
        "rf_tuned_recall = recall_score(y_test, rf_tuned_pred, average='weighted')\n",
        "rf_tuned_f1 = f1_score(y_test, rf_tuned_pred, average='weighted')\n",
        "\n",
        "print(\"=== Tuned Random Forest Results ===\")\n",
        "print(f\"Accuracy: {rf_tuned_accuracy:.4f}\")\n",
        "print(f\"Precision: {rf_tuned_precision:.4f}\")\n",
        "print(f\"Recall: {rf_tuned_recall:.4f}\")\n",
        "print(f\"F1-Score: {rf_tuned_f1:.4f}\")\n",
        "\n",
        "print(\"\\n=== Comparison (Before vs After Tuning) ===\")\n",
        "print(f\"Before Tuning - Accuracy: {rf_accuracy:.4f}, F1-Score: {rf_f1:.4f}\")\n",
        "print(f\"After Tuning - Accuracy: {rf_tuned_accuracy:.4f}, F1-Score: {rf_tuned_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7UJNcVP--n7S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['../models/tuning_classification.h5']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menyimpan Model hasil tuning\n",
        "import joblib\n",
        "joblib.dump(rf_tuned, '../models/tuning_classification.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hs4Xp4OiGEk"
      },
      "source": [
        "## 🔍 **ANALISIS: Mengapa Akurasi Klasifikasi Bisa Sempurna 100%?**\n",
        "\n",
        "### **ROOT CAUSE ANALYSIS**\n",
        "Berdasarkan investigasi mendalam, akurasi sempurna 100% terjadi karena **DATA LEAKAGE** dan **OVERFITTING**:\n",
        "\n",
        "#### **1. Perfect Feature Mapping - Location**\n",
        "```\n",
        "Location 0-10   → selalu Target 3\n",
        "Location 11-21  → selalu Target 0  \n",
        "Location 22-31  → selalu Target 2\n",
        "Location 32-43  → selalu Target 1\n",
        "```\n",
        "\n",
        "**Analogi**: Seperti ujian yang soalnya \"Jika di Jakarta, maka kategori A\". Model hanya perlu \"mengingat\" mapping ini!\n",
        "\n",
        "#### **2. Perfect Data Separation**\n",
        "- Setiap baris data adalah unik (2,182 data = 2,182 kombinasi unik)\n",
        "- Model dapat \"menghafal\" setiap kombinasi fitur\n",
        "\n",
        "#### **3. Feature Engineering Artifacts**\n",
        "- Fitur binned redundant dengan fitur asli\n",
        "- Tidak ada noise dalam data\n",
        "\n",
        "### **⚠️ MENGAPA INI MASALAH?**\n",
        "1. **Tidak Realistis**: Di dunia nyata, akurasi 100% sangat jarang\n",
        "2. **Tidak Generalizable**: Model hanya \"mengingat\", tidak belajar pola umum\n",
        "3. **Overfitting Ekstrem**: Performa buruk pada data baru\n",
        "4. **Data Leakage**: Fitur Location memberikan \"bocoran\" jawaban\n",
        "\n",
        "## Kesimpulan Analisis Klasifikasi\n",
        "\n",
        "Berdasarkan hasil analisis klasifikasi yang telah dilakukan, model berhasil memprediksi cluster target dengan akurasi yang baik. Namun, **akurasi sempurna 100% mengindikasikan adanya data leakage dan overfitting** yang perlu diperbaiki untuk implementasi real-world.\n",
        "\n",
        "**Rekomendasi untuk implementasi yang lebih baik:**\n",
        "- Hapus fitur Location yang menyebabkan perfect mapping\n",
        "- Gunakan regularization pada model\n",
        "- Implementasi cross-validation\n",
        "- Feature selection yang lebih hati-hati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🛠️ **IMPLEMENTASI KLASIFIKASI YANG DIPERBAIKI**\n",
        "\n",
        "Untuk mengatasi masalah data leakage dan overfitting, berikut implementasi yang lebih tepat:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== KLASIFIKASI TANPA DATA LEAKAGE ===\n",
            "Menghapus fitur: ['Location', 'TransactionAmount_binned', 'CustomerAge_binned']\n",
            "Fitur yang digunakan: ['TransactionAmount', 'TransactionType', 'Channel', 'CustomerAge', 'CustomerOccupation', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'TransactionAmount_binned_encoded', 'CustomerAge_binned_encoded']\n",
            "Total sampel: 2182, Total fitur: 10\n"
          ]
        }
      ],
      "source": [
        "# IMPLEMENTASI YANG DIPERBAIKI: Hapus fitur yang menyebabkan data leakage\n",
        "print(\"=== KLASIFIKASI TANPA DATA LEAKAGE ===\")\n",
        "\n",
        "# Load data original\n",
        "df_improved = pd.read_csv('../data/data_clustering.csv')\n",
        "\n",
        "# 1. Hapus fitur yang menyebabkan data leakage\n",
        "features_to_remove = [\n",
        "    'Location',                    # Perfect mapping dengan target\n",
        "    'TransactionAmount_binned',    # Redundant dengan TransactionAmount\n",
        "    'CustomerAge_binned'          # Redundant dengan CustomerAge\n",
        "]\n",
        "\n",
        "print(f\"Menghapus fitur: {features_to_remove}\")\n",
        "\n",
        "# 2. Siapkan fitur yang relevan\n",
        "X_improved = df_improved.drop(['Target'] + features_to_remove, axis=1)\n",
        "y_improved = df_improved['Target']\n",
        "\n",
        "print(f\"Fitur yang digunakan: {list(X_improved.columns)}\")\n",
        "print(f\"Total sampel: {len(X_improved)}, Total fitur: {len(X_improved.columns)}\")\n",
        "\n",
        "# 3. Normalisasi data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_improved)\n",
        "\n",
        "# 4. Split data dengan stratifikasi\n",
        "X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(\n",
        "    X_scaled, y_improved, \n",
        "    test_size=0.3, \n",
        "    random_state=42, \n",
        "    stratify=y_improved\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== TRAINING MODEL DENGAN REGULARIZATION ===\n",
            "\n",
            "Training Decision Tree (Regularized)...\n",
            "Accuracy: 0.2718, Precision: 0.2834, Recall: 0.2718, F1-Score: 0.2657\n",
            "\n",
            "Training Random Forest (Regularized)...\n",
            "Accuracy: 0.2687, Precision: 0.2643, Recall: 0.2687, F1-Score: 0.2598\n",
            "\n",
            "Training SVM (RBF)...\n",
            "Accuracy: 0.2641, Precision: 0.2634, Recall: 0.2641, F1-Score: 0.2605\n",
            "\n",
            "Training KNN...\n",
            "Accuracy: 0.2733, Precision: 0.2780, Recall: 0.2733, F1-Score: 0.2705\n",
            "\n",
            "=== CROSS-VALIDATION ANALYSIS ===\n",
            "Decision Tree (Regularized) - CV Accuracy: 0.2621 (+/- 0.0329)\n",
            "Accuracy: 0.2641, Precision: 0.2634, Recall: 0.2641, F1-Score: 0.2605\n",
            "\n",
            "Training KNN...\n",
            "Accuracy: 0.2733, Precision: 0.2780, Recall: 0.2733, F1-Score: 0.2705\n",
            "\n",
            "=== CROSS-VALIDATION ANALYSIS ===\n",
            "Decision Tree (Regularized) - CV Accuracy: 0.2621 (+/- 0.0329)\n",
            "Random Forest (Regularized) - CV Accuracy: 0.2750 (+/- 0.0179)\n",
            "Random Forest (Regularized) - CV Accuracy: 0.2750 (+/- 0.0179)\n",
            "SVM (RBF) - CV Accuracy: 0.2800 (+/- 0.0116)\n",
            "KNN - CV Accuracy: 0.2493 (+/- 0.0381)\n",
            "SVM (RBF) - CV Accuracy: 0.2800 (+/- 0.0116)\n",
            "KNN - CV Accuracy: 0.2493 (+/- 0.0381)\n"
          ]
        }
      ],
      "source": [
        "# 5. Model dengan Regularization untuk mencegah overfitting\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "print(\"\\n=== TRAINING MODEL DENGAN REGULARIZATION ===\")\n",
        "\n",
        "models_improved = {\n",
        "    'Decision Tree (Regularized)': DecisionTreeClassifier(\n",
        "        random_state=42,\n",
        "        max_depth=5,           # Batasi depth\n",
        "        min_samples_split=20,  # Minimal sampel untuk split\n",
        "        min_samples_leaf=10    # Minimal sampel di leaf\n",
        "    ),\n",
        "    'Random Forest (Regularized)': RandomForestClassifier(\n",
        "        random_state=42,\n",
        "        n_estimators=50,       # Kurangi tree\n",
        "        max_depth=5,          # Batasi depth\n",
        "        min_samples_split=20,\n",
        "        min_samples_leaf=10\n",
        "    ),\n",
        "    'SVM (RBF)': SVC(\n",
        "        random_state=42,\n",
        "        kernel='rbf',\n",
        "        C=1.0,                # Regularization parameter\n",
        "        gamma='scale'\n",
        "    ),\n",
        "    'KNN': KNeighborsClassifier(\n",
        "        n_neighbors=7         # Lebih besar dari default\n",
        "    )\n",
        "}\n",
        "\n",
        "results_improved = {}\n",
        "\n",
        "# Training dan evaluasi\n",
        "for name, model in models_improved.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    \n",
        "    # Training\n",
        "    model.fit(X_train_imp, y_train_imp)\n",
        "    \n",
        "    # Prediksi\n",
        "    y_pred_imp = model.predict(X_test_imp)\n",
        "    \n",
        "    # Evaluasi\n",
        "    accuracy_imp = accuracy_score(y_test_imp, y_pred_imp)\n",
        "    precision_imp = precision_score(y_test_imp, y_pred_imp, average='weighted')\n",
        "    recall_imp = recall_score(y_test_imp, y_pred_imp, average='weighted')\n",
        "    f1_imp = f1_score(y_test_imp, y_pred_imp, average='weighted')\n",
        "    \n",
        "    results_improved[name] = {\n",
        "        'Accuracy': accuracy_imp,\n",
        "        'Precision': precision_imp,\n",
        "        'Recall': recall_imp,\n",
        "        'F1-Score': f1_imp\n",
        "    }\n",
        "    \n",
        "    print(f\"Accuracy: {accuracy_imp:.4f}, Precision: {precision_imp:.4f}, Recall: {recall_imp:.4f}, F1-Score: {f1_imp:.4f}\")\n",
        "\n",
        "# Cross-validation untuk validasi konsistensi\n",
        "print(\"\\n=== CROSS-VALIDATION ANALYSIS ===\")\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for name, model in models_improved.items():\n",
        "    cv_scores = cross_val_score(model, X_scaled, y_improved, cv=cv, scoring='accuracy')\n",
        "    print(f\"{name} - CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "PERBANDINGAN HASIL: SEBELUM vs SESUDAH PERBAIKAN\n",
            "======================================================================\n",
            "\n",
            "📊 HASIL SEBELUM PERBAIKAN (dengan data leakage):\n",
            "Decision Tree: 100.0% accuracy\n",
            "Random Forest: 100.0% accuracy\n",
            "SVM: 100.0% accuracy\n",
            "KNN: 99.8% accuracy\n",
            "\n",
            "📊 HASIL SESUDAH PERBAIKAN (tanpa data leakage):\n",
            "                             Accuracy  Precision  Recall  F1-Score\n",
            "Decision Tree (Regularized)    0.2718     0.2834  0.2718    0.2657\n",
            "Random Forest (Regularized)    0.2687     0.2643  0.2687    0.2598\n",
            "SVM (RBF)                      0.2641     0.2634  0.2641    0.2605\n",
            "KNN                            0.2733     0.2780  0.2733    0.2705\n",
            "\n",
            "🎯 INSIGHT PENTING:\n",
            "• Akurasi ~27% untuk 4-class classification masih reasonable\n",
            "• Random baseline = 25% (1/4 classes)\n",
            "• Model sedikit lebih baik dari random guessing\n",
            "• Akurasi 100% = overfitting, akurasi ~27% = realistis\n",
            "\n",
            "✅ PERBAIKAN YANG DILAKUKAN:\n",
            "• Hapus fitur Location (perfect mapping)\n",
            "• Tambah regularization (max_depth, min_samples)\n",
            "• Normalisasi data dengan StandardScaler\n",
            "• Cross-validation untuk validasi konsistensi\n",
            "• Stratified sampling untuk distribusi seimbang\n",
            "\n",
            "💾 Model terbaik (realistis) disimpan: ../models/improved_classification_model.h5\n"
          ]
        }
      ],
      "source": [
        "# 6. Perbandingan Hasil: Sebelum vs Sesudah Perbaikan\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PERBANDINGAN HASIL: SEBELUM vs SESUDAH PERBAIKAN\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n📊 HASIL SEBELUM PERBAIKAN (dengan data leakage):\")\n",
        "print(\"Decision Tree: 100.0% accuracy\")\n",
        "print(\"Random Forest: 100.0% accuracy\") \n",
        "print(\"SVM: 100.0% accuracy\")\n",
        "print(\"KNN: 99.8% accuracy\")\n",
        "\n",
        "print(\"\\n📊 HASIL SESUDAH PERBAIKAN (tanpa data leakage):\")\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results_improved).T\n",
        "print(results_df.round(4))\n",
        "\n",
        "print(\"\\n🎯 INSIGHT PENTING:\")\n",
        "print(\"• Akurasi ~27% untuk 4-class classification masih reasonable\")\n",
        "print(\"• Random baseline = 25% (1/4 classes)\")\n",
        "print(\"• Model sedikit lebih baik dari random guessing\")\n",
        "print(\"• Akurasi 100% = overfitting, akurasi ~27% = realistis\")\n",
        "\n",
        "print(\"\\n✅ PERBAIKAN YANG DILAKUKAN:\")\n",
        "print(\"• Hapus fitur Location (perfect mapping)\")\n",
        "print(\"• Tambah regularization (max_depth, min_samples)\")\n",
        "print(\"• Normalisasi data dengan StandardScaler\")\n",
        "print(\"• Cross-validation untuk validasi konsistensi\")\n",
        "print(\"• Stratified sampling untuk distribusi seimbang\")\n",
        "\n",
        "# Simpan model terbaik (yang realistis)\n",
        "best_model_improved = models_improved['KNN']  # KNN memiliki performa terbaik\n",
        "import joblib\n",
        "joblib.dump(best_model_improved, '../models/improved_classification_model.h5')\n",
        "print(f\"\\n💾 Model terbaik (realistis) disimpan: ../models/improved_classification_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
